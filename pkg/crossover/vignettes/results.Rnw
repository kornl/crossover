\documentclass[a4paper, 10pt]{article}
\usepackage{natbib}
\bibliographystyle{plainnat}
\usepackage[T1]{fontenc}
\usepackage{url}
 \usepackage[utf8]{inputenc}
\usepackage{graphicx}
%\usepackage{tikz}
%\usetikzlibrary{decorations,arrows,shapes}
\usepackage[margin=0.9in]{geometry}
%\usepackage[left=3cm,right=3cm,top=2cm,bottom=2cm]{geometry}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xspace}
\usepackage{tabularx}
\usepackage{makeidx}\makeindex
\usepackage{algorithmic} 
\usepackage{algorithm}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\setlength{\parindent}{0mm}
\setlength{\parskip}{1mm}
\newcommand{\commentout}[1]{}
\renewcommand{\theequation}{\thesection.\arabic{\equation}}
\numberwithin{equation}{section}

\theoremstyle{definition}
\newtheorem{Def}{Definition}[section]
\newtheorem{Rem}[Def]{Remark}
\newtheorem{RemDef}[Def]{Remark und Definition}
\newtheorem{DefRem}[Def]{Definition und Remark}
\newtheorem{Example}[Def]{Example}
\theoremstyle{plain}
\newtheorem{Theorem}[Def]{Theorem}
\newtheorem{DefTheorem}[Def]{Definition and Theorem}
\newtheorem{Corollary}[Def]{Corollary}
\newtheorem{Lemma}[Def]{Lemma}

\newcommand{\C}{\ensuremath{\mathbb{C}}\xspace}
\newcommand{\R}{\ensuremath{\mathbb{R}}\xspace}
\newcommand{\Q}{\ensuremath{\mathbb{Q}}\xspace}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}\xspace}
\newcommand{\NN}{\ensuremath{\mathbb{N}_0}\xspace}
\newcommand{\N}{\ensuremath{\mathbb{N}}\xspace}
\newcommand{\sF}{\ensuremath{\mathcal{F}}\xspace}
\newcommand{\sN}{\ensuremath{\mathcal{N}}\xspace}
\newcommand{\Pot}{\ensuremath{\mathfrak{Pot}}\xspace}
\newcommand{\kronecker}{\raisebox{1pt}{\ensuremath{\:\otimes\:}}}

\DeclareMathOperator{\range}{range}

\newcommand{\skp}[1]{\left\langle#1\right\rangle}

\renewcommand{\epsilon}{\varepsilon}
\renewcommand{\phi}{\varphi}
\newcommand{\id}{\text{id}}

\newenvironment{Proof}{\par\noindent\upshape\textit{Proof. }\nopagebreak}{\qed\par}

\usepackage{setspace}
\onehalfspacing

\begin{document}

%\VignetteEngine{knitr}
%\VignetteIndexEntry{crossover - Comparing results}

<<include=FALSE, message=FALSE>>=
if (exists("opts_chunk")) {
  opts_chunk$set(concordance=TRUE)
  opts_chunk$set(tidy.opts=list(keep.blank.line=FALSE, width.cutoff=95))
  #opts_chunk$set(size="footnotesize")
  #opts_chunk$set(size="tiny")
  opts_chunk$set(size="scriptsize") 
}
library(crossover, quietly=TRUE)
options(width=128)
options(digits=4)
startGUI <- function(...) {invisible(NULL)}
#options(prompt="> ", continue="+ ")
library(MASS)
library(multcomp)
library(ggplot2)
library(Matrix)
@

\subsection*{Evaluation of Algorithm Performance}

We compare our results with results from the algorithm of \cite{john2004crossover} that are presented in \cite[table~4.35-4.38, p.~215]{jones2003design} for s=6 sequences, p=4 periods and v=2 treatments.

<<echo=FALSE, eval=TRUE, cache=TRUE>>=
s <- 6; p <- 4; v <- 2

design1 <- t(rbind(c(1,1,2,2),
                   c(2,2,1,1),
                   c(1,1,2,2),
                   c(2,2,1,1),
                   c(1,2,2,1),
                   c(2,1,1,2)))
design2 <- t(rbind(c(1,1,2,1),
                   c(2,2,1,2),
                   c(1,1,2,1),
                   c(2,2,1,2),
                   c(1,2,2,1),
                   c(2,1,1,2)))
design3 <- t(rbind(c(1,1,2,2),
                   c(2,2,1,1),
                   c(1,1,2,2),
                   c(2,2,1,1),
                   c(1,1,2,2),
                   c(2,2,1,1)))
design4 <- t(rbind(c(1,1,2,2), # TODO Also correct in other version
                   c(2,2,1,1),
                   c(1,1,2,2),
                   c(2,2,1,1),
                   c(1,2,2,1),
                   c(2,1,1,2))) # Why is there no design 4 in the book?
design5 <- t(rbind(c(1,2,2,2),
                   c(2,1,1,1),
                   c(1,2,2,2),
                   c(2,1,1,1),
                   c(1,1,2,2),
                   c(2,2,1,1)))
design6 <- t(rbind(c(1,2,1,2),
                   c(2,1,2,1),
                   c(1,1,2,1),
                   c(2,2,1,2),
                   c(1,2,1,2),
                   c(2,1,2,1)))
design7 <- t(rbind(c(1,1,2,1),
                   c(2,2,1,2),
                   c(1,1,1,2),
                   c(2,2,2,1),
                   c(1,2,1,1),
                   c(2,1,2,2)))
design8 <- t(rbind(c(1,2,2,2),
                   c(2,1,1,1),
                   c(1,1,2,2),
                   c(2,2,1,1),
                   c(1,2,1,2),
                   c(2,1,2,1)))

designs <- list(design1, design2, design3, design4, design5, design6, design7, design8)

models <- c("Standard additive model",
            "Self-adjacency model",
            "Proportionality model",
            "Placebo model",
            "No carry-over into self model",
            "Treatment decay model",
            "Full set of interactions",
            "Second-order carry-over effects")

for (i in 1:8) {  
    model <- models[i]
    cat("======= ", model, " =======","\n")
    for (k in 1:3) {
        result <- searchCrossOverDesign(s=s, p=p, v=v, model=model) #, start.designs=list(designs[[i]]))
        print(getDesign(result))
        cat("\nTreatment: ", general.carryover(designs[[i]], model=i)$Var.trt.pair[1,2]/4, "(literature) vs. ", general.carryover(result)$Var.trt.pair[1,2]/4,"\n")
        gco <- general.carryover(designs[[i]], model=i)
        if (!is.null(dim(gco[[2]]))) {
            cat("(1st) Carryover: ", gco[[2]][1,2]/4, "(literature) vs. ", general.carryover(result)[[2]][1,2]/4,"\n\n")
        }
    }
}    

@

Note that for the full interaction model and the self-adjacency model we get the same results, because they are essentially the same models with \begin{equation*}
\begin{split}
\lambda^{SA}_1&=\lambda^{FI}_1+\gamma^{FI}_{12},\\
\lambda^{SA}_2&=\lambda^{FI}_2+\gamma^{FI}_{21},\\
\phi^{SA}_1&=\lambda^{FI}_1+\gamma^{FI}_{11},\text{ and}\\
\phi^{SA}_2&=\lambda^{FI}_2+\gamma^{FI}_{22}.
\end{split}
\end{equation*}

For the treatment decay model the algorithm provided us with Let's give a little bit of weight to the carry-over effects:

<<echo=FALSE>>=

i <- 6

Csub <- contrMat(n=rep(1, v), type="Tukey")
class(Csub) <- "matrix"

C <- as.matrix(bdiag(Csub, Csub))
result <- searchCrossOverDesign(s=s, p=p, v=v, model=i, contrast=C)
cat("Equal weight\n")
print(getDesign(result))
cat("\nTreatment: ", general.carryover(designs[[i]], model=i)$Var.trt.pair[1,2]/4, "(literature) vs. ", general.carryover(result)$Var.trt.pair[1,2]/4,"\n")
gco <- general.carryover(designs[[i]], model=i)
cat("(1st) Carryover: ", gco[[2]][1,2]/4, "(literature) vs. ", general.carryover(result)[[2]][1,2]/4,"\n\n")

C <- as.matrix(bdiag(Csub, 0.1*Csub))
result <- searchCrossOverDesign(s=s, p=p, v=v, model=i, contrast=C)
cat("Weight 10:1\n")
print(getDesign(result))
cat("\nTreatment: ", general.carryover(designs[[i]], model=i)$Var.trt.pair[1,2]/4, "(literature) vs. ", general.carryover(result)$Var.trt.pair[1,2]/4,"\n")
gco <- general.carryover(designs[[i]], model=i)
cat("(1st) Carryover: ", gco[[2]][1,2]/4, "(literature) vs. ", general.carryover(result)[[2]][1,2]/4,"\n\n")

C <- as.matrix(bdiag(Csub, 0.01*Csub))
result <- searchCrossOverDesign(s=s, p=p, v=v, model=i, contrast=C)
cat("Weight 100:1\n")
print(getDesign(result))
cat("\nTreatment: ", general.carryover(designs[[i]], model=i)$Var.trt.pair[1,2]/4, "(literature) vs. ", general.carryover(result)$Var.trt.pair[1,2]/4,"\n")
gco <- general.carryover(designs[[i]], model=i)
cat("(1st) Carryover: ", gco[[2]][1,2]/4, "(literature) vs. ", general.carryover(result)[[2]][1,2]/4,"\n\n")


@

<<>>=
for (p in c("multcomp","Matrix","crossover")) require(p, character.only=TRUE)

s <- 6; p <- 4; v <- 2; model <- 6

result <- searchCrossOverDesign(s=s, p=p, v=v, model=model, contrast="Tukey", eff.factor=c(1,0.01))

Csub <- contrMat(n=rep(1, v), type="Tukey")
class(Csub) <- "matrix"
C <- as.matrix(bdiag(Csub, 0.01*Csub))
result <- searchCrossOverDesign(s=s, p=p, v=v, model=model, contrast=C)

@

As we can see we find the design from the book, when we give weights 100:1 for treatment / carry-over effects in the treatment decay model.
(As seen in the first result section a zero weight for the carry-over effects results in a model with alternating treatments, so that there never occurs a treatment decay effect.)

\subsection*{Comparisons to control}

<<echo=FALSE>>=

s<-8; p<-6; v<-4
i <- 1

Csub <- contrMat(n=rep(1, v), type="Dunnett")
class(Csub) <- "matrix"
#C <- as.matrix(bdiag(Csub, Csub))
C <- crossover:::appendZeroColumns(Csub, model=i, v)
C

result <- searchCrossOverDesign(s=8, p=6, v=4, model=i, contrast=C)
result
result <- searchCrossOverDesign(s=8, p=6, v=4, model=i)
result

@

\subsection*{Williams designs}

Now we try to find some Williams designs (with a short search of only a few seconds) - we had already an email discussion about the problem that the williams5t is normally not found with the short default search (it was found (multiple times), when we increased the search to for example $n=c(5000,1000)$):

<<echo=FALSE, eval=TRUE, cache=TRUE>>=
data(williams)
for (v in 3:9) {
    name <- paste("williams",v,"t",sep="")
    design <- get(name)
    p <- dim(design)[1]
    s <- dim(design)[2]
    cat("Searching for",name,"\n")
    result <- searchCrossOverDesign(s=s, p=p, v=v, model=1)
    print(getDesign(result))
    cat("av.eff.trt.pair.adj: ", design.efficiency(design)$av.eff.trt.pair.adj, "(Williams) vs. ", design.efficiency(result)$av.eff.trt.pair.adj, "\n\n")
}

@

\subsection*{Autocorrelated errors}


<<echo=FALSE>>=

propSummary <- function(design) {
    print(design)    
    while (!is.null(dim(design)) && dim(design)[2]>0) {
        col <- design[,1]
        g <- apply(design, 2, function(x) {all(x==col)})
        cat(col, " : ", sum(g), "\n")
        design <- design[,-which(g), drop = FALSE]        
    }
}

@


Laska and Meisner

For the specified $N_k$ the variance of the BLUE (only for the BLUE?) is

\[\text{var}(\hat\theta)=m'A^{-1}m\]
with $A=\sum N_k X_k'C^{-1}X_k$.

<<>>=

p <- 6; s <- 8; v <- 2
sigmaE <- 1

C <- matrix(1,6,6)
C <- as.matrix(bdiag(C,C,C,C,C,C,C,C))+diag(6*8)
CI <- solve(C)
x1 <- c(1,2,2,1,1,2)
x2 <- c(2,1,1,2,2,1)
y1 <- c(1,1,2,2,2,1)
y2 <- c(2,2,1,1,1,2)

z1 <- c(1,2,2,2,1,1)
z2 <- c(2,1,1,1,2,2)

w1 <- c(1,2,2,1,1,2)
w2 <- c(2,1,1,2,2,1)

ldesign1 <- cbind(x1,x2,y1,y2,x1,x2,y1,y2)
ldesign2 <- cbind(x1,x2,z1,z2,x1,x2,z1,z2)
ldesign3 <- cbind(x1,x2,y1,y2,z1,z2,w1,w2)

result1 <- searchCrossOverDesign(s=s, p=p, v=v, model=1, correlation=CI, n = c(5000, 40), start.designs=list(ldesign1, ldesign2, ldesign3))
propSummary(getDesign(result1))
plot(result1)

result2 <- searchCrossOverDesign(s=s, p=p, v=v, model=1, correlation=CI, n = c(5000, 40), start.designs=list(ldesign1, ldesign2, ldesign3), random.subject=TRUE)
propSummary(getDesign(result2))
plot(result2)

@

Two treatments and autocorrelated error:

<<>>=

getSigmaI <- function(rho, s, p, f=solve) {
    V <- diag(p)
    for (i in 1:p) {
        for (j in 1:p) {
            V[i,j] <- rho^abs(i-j)
        }
    }
    # Our design matrix is indexed p=1,1,1,2,2,2,3,3,3; s=1,2,3,1,2,3,1,2,3 therefore we have to exchange the arguments:
    sigmaI <- kronecker(f(V), diag(s)) #kronecker(diag(s), f(V))
    return(sigmaI)
}

@

Case 1: $-1<\rho\leq0$

<<>>=

Csub <- contrMat(n=rep(1, v), type="Tukey")
class(Csub) <- "matrix"

C <- diag(4) #as.matrix(bdiag(Csub, Csub))

p <- 3; v <-2; s<-10

for (rho in ((1:9)/5-1)) {
    cat("Rho =", rho,":\n")
    result <- searchCrossOverDesign(s=s, p=p, v=v, model=1, correlation=getSigmaI(rho, s=s, p=p), contrast=C)
    propSummary(getDesign(result))
}

p <- 4

for (rho in c(-0.5, 0, 0.5)) {
    cat("Rho =", rho,":\n")
    result <- searchCrossOverDesign(s=s, p=p, v=v, model=1, correlation=getSigmaI(rho, s=s, p=p))
    propSummary(getDesign(result))
}

cc <- 4*rho*(1-rho)^2
k <- cc/(rho^2-3*rho+4)
d <- 11-rho-cc
x <- max(0, (2*k+d-d*sqrt(1+k*rho))/(cc*sqrt(1-k*rho)))

@

\subsection*{Incomplete block design}

<<>>=
v <- 6; p <- 4; s <- 24

result0 <- searchCrossOverDesign(s=s, p=p, v=v, model=1)
# Further results were computed only once (since it took ~ 5 minutes) and now loaded: 
#load("/home/kornel/git/crossover/pkg/crossover/vignettes/BIBD_6_4_24_5000_1000.RData")
#load("/home/kornel/git/crossover/pkg/crossover/vignettes/BIBD_6_4_24_50000_100.RData")
#load("/home/kornel/git/crossover/pkg/crossover/vignettes/BIBD_6_4_24_250000_20.RData")
data(pattersonLucasPBIBD)
pattersonLucasPBIBD134

design.efficiency(pattersonLucasPBIBD134)$av.eff.trt.pair.adj

plot(result0) + ylim(0.5, 0.85) + ggtitle(sprintf("Default setting (20 runs with 5.000 steps each): %.4f", design.efficiency(result0)$av.eff.trt.pair.adj))
#plot(result3) + ylim(0.5, 0.85) + ggtitle(sprintf("20 runs with 250.000 steps each: %.4f", design.efficiency(result3)$av.eff.trt.pair.adj))
#plot(result2) + ylim(0.5, 0.85) + ggtitle(sprintf("100 runs with 50.000 steps each: %.4f", design.efficiency(result2)$av.eff.trt.pair.adj))

# And 1000 runs a 5000 steps is actually even better:
design.efficiency(result0)$av.eff.trt.pair.adj

#result0 <- searchCrossOverDesign(s=s, p=p, v=v, model=1, start.designs=list(pattersonLucasPBIBD134), n=c(2,200))

@

\bibliography{literatur}

\end{document}
